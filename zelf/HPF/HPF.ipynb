{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hpfrec import HPF\n",
    "import heapq\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "randseed = 42\n",
    "print(\"Random seed:\", randseed)\n",
    "np.random.seed(randseed)\n",
    "\n",
    "dir_ml = 'C:/Users/Sten Stokroos/Desktop/NEW/zelf/Data/out/'\n",
    "\n",
    "def choose_data(dat, test_size, fold=0, n_folds=5):\n",
    "    if dat == 'ml2':\n",
    "        train = pd.read_csv(os.path.join(dir_ml, 'ml_train2.csv'), sep=\"\\t\", header=None, names=['userId', 'songId', 'rating'], usecols=[0, 1, 2], engine=\"python\")\n",
    "        test = pd.read_csv(os.path.join(dir_ml, 'ml_test2.csv'), sep=\"\\t\", header=None, names=['userId', 'songId', 'rating'], usecols=[0, 1, 2], engine=\"python\")\n",
    "        user_ids = train['userId'].unique()\n",
    "        item_ids = train['songId'].unique()\n",
    "\n",
    "        n_users = len(user_ids)\n",
    "        n_items = len(item_ids)\n",
    "\n",
    "        val = None  # Assuming no validation set for 'ml2'\n",
    "    elif dat == 'ml':\n",
    "        ml_full = pd.read_csv(os.path.join(dir_ml, 'ml-1m_full.csv'), sep=\"\\t\", header=None, names=['userId', 'songId', 'rating'], usecols=[0, 1, 2], engine=\"python\")\n",
    "\n",
    "        user_ids = ml_full['userId'].unique()\n",
    "        item_ids = ml_full['songId'].unique()\n",
    "\n",
    "        n_users = len(user_ids)\n",
    "        n_items = len(item_ids)\n",
    "        \n",
    "        # Split user IDs for train and test sets\n",
    "        train, test = train_test_split(ml_full, test_size=test_size, random_state=42)\n",
    "\n",
    "        # Shuffle the training set\n",
    "        train = train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        # Create folds for cross-validation\n",
    "        fold_size = int(len(train) / n_folds)\n",
    "        val = train.iloc[fold * fold_size: (fold + 1) * fold_size]\n",
    "        \n",
    "        # Remaining data is the training set for this fold\n",
    "        train = pd.concat([train.iloc[:fold * fold_size], train.iloc[(fold + 1) * fold_size:]]).reset_index(drop=True)\n",
    "    else:\n",
    "        print('Wrong data input')\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Print the sizes of the datasets\n",
    "    print(f\"Train set size: {train.shape[0]} ratings\")\n",
    "    print(f\"Validation set size: {val.shape[0]} ratings\")\n",
    "    print(f\"Test set size: {test.shape[0]} ratings\")\n",
    "\n",
    "    return train, val, test, n_users, n_items\n",
    "\n",
    "ml = 'ml'\n",
    "\n",
    "# Define evaluation functions\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i + 2)\n",
    "    return 0\n",
    "\n",
    "def eval_one_rating(idx, model, test_ratings, test_negatives, topk):\n",
    "    rating = test_ratings[idx]\n",
    "    user = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    items = test_negatives[idx]\n",
    "    items.append(gtItem)\n",
    "    \n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), user, dtype='int32')\n",
    "    predictions = model.predict(user=users, item=np.array(items))\n",
    "    \n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    items.pop()\n",
    "    \n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(topk, map_item_score, key=map_item_score.get)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    return ndcg\n",
    "\n",
    "k_values = [32]\n",
    "n_folds = 5\n",
    "test_size = 0.1\n",
    "\n",
    "def load_negative_file(filename):\n",
    "    negativeList = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            negatives = []\n",
    "            for x in arr[1:]:\n",
    "                negatives.append(int(x))\n",
    "            negativeList.append(negatives)\n",
    "            line = f.readline()\n",
    "    return negativeList\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    print(f\"Processing fold {fold+1}/{n_folds}...\")\n",
    "    train_df, val_df, test_df, num_users, num_items = choose_data(ml, test_size, fold=fold, n_folds=n_folds)\n",
    "\n",
    "    # Load negative samples for the current fold\n",
    "    negative_samples_file = f'C:/Users/Sten Stokroos/Desktop/NEW/zelf/Data/out/ml2_negatives_fold_{fold}.csv'\n",
    "    test_negatives = load_negative_file(negative_samples_file)\n",
    "\n",
    "    # Rename columns to 'UserId', 'ItemId', 'Count'\n",
    "    train_df = train_df.rename(columns={'userId': 'UserId', 'songId': 'ItemId', 'rating': 'Count'})\n",
    "    val_df = val_df.rename(columns={'userId': 'UserId', 'songId': 'ItemId', 'rating': 'Count'})\n",
    "    test_df = test_df.rename(columns={'userId': 'UserId', 'songId': 'ItemId', 'rating': 'Count'})\n",
    "\n",
    "    # Convert ratings to binary exposure data (1 if Count > 0, else 0)\n",
    "    train_df['Count'] = (train_df['Count'] > 0).astype(int)\n",
    "    val_df['Count'] = (val_df['Count'] > 0).astype(int)\n",
    "    test_df['Count'] = (test_df['Count'] > 0).astype(int)\n",
    "\n",
    "    # Get unique user and item IDs\n",
    "    all_observed_df = pd.concat([train_df, val_df, test_df])\n",
    "    user_ids = all_observed_df['UserId'].unique()\n",
    "    item_ids = all_observed_df['ItemId'].unique()\n",
    "\n",
    "    test_ratings = test_df[['UserId', 'ItemId']].values.tolist()\n",
    "\n",
    "    for k in k_values:\n",
    "        print(f\"Training HPF model with k={k} for fold {fold+1}...\")\n",
    "        recommender = HPF(\n",
    "            k=k, a=0.3, a_prime=0.3, b_prime=1.0,\n",
    "            c=0.3, c_prime=0.3, d_prime=1.0, ncores=-1,\n",
    "            stop_crit='train-llk', check_every=10, stop_thr=1e-3,\n",
    "            users_per_batch=None, items_per_batch=None, step_size=lambda x: 1/np.sqrt(x+2),\n",
    "            maxiter=100, use_float=True, reindex=False, verbose=True,\n",
    "            random_seed=None, allow_inconsistent_math=False, full_llk=False,\n",
    "            alloc_full_phi=False, keep_data=True, save_folder=None,\n",
    "            produce_dicts=True, keep_all_objs=True, sum_exp_trick=False\n",
    "        )\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        recommender.fit(train_df, val_df)\n",
    "        topk = 10\n",
    "\n",
    "        # Calculate log-likelihood on the validation set\n",
    "        llk = recommender.eval_llk(val_df)\n",
    "        print(f\"Log-likelihood for k={k}, fold {fold+1}: {llk['llk']}\")\n",
    "\n",
    "        # Evaluate the model using NDCG\n",
    "        ndcg_scores = [eval_one_rating(i, recommender, test_ratings, test_negatives, topk) for i in tqdm(range(len(test_ratings)))]\n",
    "        avg_ndcg = np.mean(ndcg_scores)\n",
    "        print(f\"Average NDCG for k={k}, fold {fold+1}: {avg_ndcg}\")\n",
    "\n",
    "        # Initialize an empty matrix for exposures\n",
    "        exposure_matrix = np.zeros((len(user_ids), len(item_ids)))\n",
    "\n",
    "        # Predict the exposure data for all user-item pairs\n",
    "        for i, user in enumerate(user_ids):\n",
    "            exposures = recommender.predict(user=[user] * len(item_ids), item=item_ids)\n",
    "            exposure_matrix[i, :] = exposures\n",
    "\n",
    "        # Convert the exposure matrix to a DataFrame\n",
    "        exposure_df = pd.DataFrame(exposure_matrix, index=user_ids, columns=item_ids)\n",
    "\n",
    "        # Save the exposure matrix to a CSV file with k and fold in the file name\n",
    "        output_file = f'C:/Users/Sten Stokroos/Desktop/NEW/zelf/Data/exposure_output/ml_exp_k_{k}_fold_{fold+1}.csv'\n",
    "        exposure_df.to_csv(output_file, index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
