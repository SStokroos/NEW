{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Use the function\u001b[39;00m\n\u001b[0;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m pmf\u001b[38;5;241m.\u001b[39mPoissonMF(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, smoothness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m proportion_better \u001b[38;5;241m=\u001b[39m predictive_check_with_vad(model, train_sparse, vad_sparse)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProportion of simulated datasets with higher log-likelihood than validation data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, proportion_better)\n",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m, in \u001b[0;36mpredictive_check_with_vad\u001b[1;34m(model, train_data, vad_data, n_simulations)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Step 2: Calculate log-likelihood of the validation data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m vad_rows, vad_cols \u001b[38;5;241m=\u001b[39m vad_data\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[1;32m---> 16\u001b[0m actual_vad_loglik \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpred_loglikeli(vad_data, vad_rows, vad_cols)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Step 3: Simulate datasets and calculate their log-likelihoods\u001b[39;00m\n\u001b[0;32m     19\u001b[0m simulated_logliks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Sten Stokroos\\Desktop\\zelf\\src\\causalrec\\pmf.py:185\u001b[0m, in \u001b[0;36mPoissonMF.pred_loglikeli\u001b[1;34m(self, X_new, rows_new, cols_new)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpred_loglikeli\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_new, rows_new, cols_new):\n\u001b[0;32m    184\u001b[0m     X_pred \u001b[38;5;241m=\u001b[39m _inner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEt, rows_new, cols_new)\n\u001b[1;32m--> 185\u001b[0m     pred_ll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X_new \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(X_pred) \u001b[38;5;241m-\u001b[39m X_pred)\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred_ll\n",
      "File \u001b[1;32mc:\\Users\\Public\\ana\\Lib\\site-packages\\scipy\\sparse\\_matrix.py:48\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_dispatch(other)\n",
      "File \u001b[1;32mc:\\Users\\Public\\ana\\Lib\\site-packages\\scipy\\sparse\\_base.py:553\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# dense row or column vector\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (N,) \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (N, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 553\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    555\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_vector(np\u001b[38;5;241m.\u001b[39mravel(other))\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, np\u001b[38;5;241m.\u001b[39mmatrix):\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pmf\n",
    "import pandas as pd\n",
    "import  tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "def predictive_check_with_vad(model, train_data, vad_data, n_simulations=50):\n",
    "    # Step 1: Fit the model on the training data\n",
    "    train_rows, train_cols = train_data.nonzero()\n",
    "    model.fit(train_data, train_rows, train_cols)\n",
    "\n",
    "    # Step 2: Calculate log-likelihood of the validation data\n",
    "    vad_rows, vad_cols = vad_data.nonzero()\n",
    "    actual_vad_loglik = model.pred_loglikeli(vad_data, vad_rows, vad_cols)\n",
    "\n",
    "    # Step 3: Simulate datasets and calculate their log-likelihoods\n",
    "    simulated_logliks = []\n",
    "    for _ in tqdm(range(n_simulations)):\n",
    "        # Generate a simulated dataset from the model\n",
    "        simulated_data = model.generate_replicated_data()\n",
    "        simulated_loglik = model.pred_loglikeli(simulated_data, vad_rows, vad_cols)\n",
    "        simulated_logliks.append(simulated_loglik)\n",
    "\n",
    "    # Step 4: Compare simulated log-likelihoods to actual validation log-likelihood\n",
    "    proportion_better = np.mean([loglik > actual_vad_loglik for loglik in simulated_logliks])\n",
    "\n",
    "    return proportion_better\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('C:/Users/Sten Stokroos/Desktop/zelf/dat/proc/ml_wg/train.csv')\n",
    "vad_data = pd.read_csv('C:/Users/Sten Stokroos/Desktop/zelf/dat/proc/ml_wg/validation.csv')\n",
    "\n",
    "def convert_to_csr(df):\n",
    "    # Ensure user IDs and item IDs are integers and zero-indexed\n",
    "    user_ids = df['uid'].astype(int)\n",
    "    item_ids = df['sid'].astype(int)\n",
    "    ratings = df['rating'].astype(float)\n",
    "\n",
    "    # Get the maximum indices for matrix dimensions\n",
    "    n_users = user_ids.max() + 1\n",
    "    n_items = item_ids.max() + 1\n",
    "\n",
    "    # Create a sparse matrix\n",
    "    return csr_matrix((ratings, (user_ids, item_ids)), shape=(n_users, n_items))\n",
    "\n",
    "train_sparse = convert_to_csr(train_data)\n",
    "vad_sparse = convert_to_csr(vad_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the function\n",
    "model = pmf.PoissonMF(n_components=100, max_iter=100, smoothness=100, random_state=42, a=0.3, b=0.3, c=0.3, d=0.3)\n",
    "proportion_better = predictive_check_with_vad(model, train_sparse, vad_sparse)\n",
    "print(\"Proportion of simulated datasets with higher log-likelihood than validation data:\", proportion_better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
