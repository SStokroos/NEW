{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed:  42\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "dir_ml = 'C:/Users/Sten Stokroos/Desktop/NEW/zelf/Data/out'\n",
    "randseed = 42\n",
    "print(\"random seed: \", randseed)\n",
    "np.random.seed(randseed)\n",
    "\n",
    "def choose_data(dat, test_size, val_size, random_seed):\n",
    "    if dat == 'ml2':\n",
    "        train = pd.read_csv(os.path.join(dir_ml, 'ml_train2.csv'), sep=\"\\t\", header=None, names=['userId', 'songId', 'rating'], usecols=[0, 1, 2], engine=\"python\")\n",
    "        test = pd.read_csv(os.path.join(dir_ml, 'ml_test2.csv'), sep=\"\\t\", header=None, names=['userId', 'songId', 'rating'], usecols=[0, 1, 2], engine=\"python\")\n",
    "        train, val = train_test_split(ml_full, test_size=test_size, random_state=random_seed)\n",
    "\n",
    "        user_ids = train['userId'].unique()\n",
    "        item_ids = train['songId'].unique()\n",
    "        n_users = len(user_ids)\n",
    "        n_items = len(item_ids)\n",
    "    elif dat == 'ml':\n",
    "        ml_full = pd.read_csv(os.path.join(dir_ml, 'ml-1m_full.csv'), sep=\"\\t\", header=None, names=['userId', 'songId', 'rating'], usecols=[0, 1, 2], engine=\"python\")\n",
    "        user_ids = ml_full['userId'].unique()\n",
    "        item_ids = ml_full['songId'].unique()\n",
    "        n_users = len(user_ids)\n",
    "        n_items = len(item_ids)\n",
    "        train, test = train_test_split(ml_full, test_size=test_size, random_state=random_seed) #ADD VAL SETS FOR DATA SPLITS AS IN THESIS, ALSO IN THE GENERATIN PROCESS OF THE CONFOUDNERS \n",
    "    else:\n",
    "        print('Wrong data input')\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    print(f\"Train set size: {train.shape[0]} ratings\")\n",
    "    print(f\"Test set size: {test.shape[0]} ratings\")\n",
    "    return train, val, test, n_users, n_items\n",
    "\n",
    "\n",
    "def load_confounders(dat, k, contype):\n",
    "    CAUSEFIT_DIR = f'C:/Users/Sten Stokroos/Desktop/NEW/zelf/Data/exposure_output/{dat}_{contype}_exp_k_{k}.csv' #ADD FIXES TO MATCH DATA SPLITS\n",
    "    conf_df = pd.read_csv(CAUSEFIT_DIR, header=None)\n",
    "    confounder_data = conf_df.to_numpy().T\n",
    "    return confounder_data\n",
    "\n",
    "def load_data_rating(dat, columns=[0, 1, 2], sep=\"\\t\", include_validation=False, test_size=0.1, val_size=0.1, random_seed=None):\n",
    "    train, val, test, n_users, n_items = choose_data(dat, test_size, val_size, random_seed)\n",
    "\n",
    "    def build_matrix(df):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        ratings = []\n",
    "        for line in df.itertuples():\n",
    "            rows.append(line[1])\n",
    "            cols.append(line[2])\n",
    "            ratings.append(line[3])\n",
    "        return csr_matrix((ratings, (rows, cols)), shape=(n_users, n_items)).todok()\n",
    "\n",
    "    train_matrix = build_matrix(train)\n",
    "    test_matrix = build_matrix(test)\n",
    "\n",
    "    print(\"Load data finished. Number of users:\", n_users, \"Number of items:\", n_items)\n",
    "    return train_matrix, test_matrix, n_users, n_items\n",
    "\n",
    "\n",
    "def run_model(module_name, class_name, k, contype='hpf', dat='ml', use_confounder=False, use_exposure=False, test_size=0.1, val_size=0.1, \n",
    "              hidden_neuron=500, learning_rate=0.001, reg_rate=0.1, epoch=20, batch_size=200, verbose=False, T=1, display_step=1000, save_path=None, num_runs=5):\n",
    "    \n",
    "    best_rmse_values = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        random_seed = np.random.randint(10000)  # Generate a new random seed for each run\n",
    "        print(f'random seed run {run}: {random_seed}')\n",
    "        train, test, n_users, n_items = load_data_rating(dat, columns=[0, 1, 2], sep=\"\\t\", test_size=test_size, val_size=val_size, random_seed=random_seed)\n",
    "        print(f\"Loaded data: train={train.shape}, test={test.shape}, user={n_users}, item={n_items}\")\n",
    "\n",
    "        confounder_data = None\n",
    "        exposure_data = None\n",
    "\n",
    "        if use_confounder:\n",
    "            confounder_data = load_confounders(dat, k, contype)\n",
    "        if use_exposure:\n",
    "            exposure_data = (train > 0).astype(np.float32).todense().T\n",
    "\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "\n",
    "        with tf.compat.v1.Session(config=config) as sess:\n",
    "            module = importlib.import_module(module_name)\n",
    "            model_class = getattr(module, class_name)\n",
    "\n",
    "            final_model = model_class(sess, n_users, n_items, learning_rate=learning_rate, reg_rate=reg_rate, epoch=epoch, batch_size=batch_size, verbose=verbose, T=T, display_step=display_step)\n",
    "            final_model.build_network(hidden_neuron=hidden_neuron)\n",
    "            \n",
    "            if confounder_data is not None and exposure_data is not None:\n",
    "                final_model.execute(train, test, confounder_data, exposure_data)\n",
    "            elif confounder_data is not None:\n",
    "                final_model.execute(train, test, confounder_data)\n",
    "            else:\n",
    "                final_model.execute(train, test)\n",
    "\n",
    "            best_rmse_values.append(np.min(final_model.test_rmse_history))\n",
    "            if save_path:\n",
    "                class_folder = os.path.join(save_path, class_name.lower())\n",
    "                os.makedirs(class_folder, exist_ok=True)\n",
    "                np.save(os.path.join(class_folder, f'{contype}{epoch}_runssplit_{run}_train_loss_{dat}_k{k}.npy'), np.array(final_model.train_loss_history))\n",
    "                np.save(os.path.join(class_folder, f'{contype}{epoch}_run_{run}_test_rmse_{dat}_k{k}.npy'), np.array(final_model.test_rmse_history))\n",
    "\n",
    "    if save_path:\n",
    "        class_folder = os.path.join(save_path, class_name.lower())\n",
    "        np.save(os.path.join(class_folder, f'{contype}{epoch}_best_rmse_values_{dat}_k{k}.npy'), np.array(best_rmse_values))\n",
    "\n",
    "    avg_best_rmse = np.mean(best_rmse_values)\n",
    "    print(f\"Average Best RMSE: {avg_best_rmse}\")\n",
    "\n",
    "    return best_rmse_values\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UAutoRec with k=32, use_confounder=False, use_exposure=False\n",
      "random seed run 0: 7270\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/200 [13:58<46:21:56, 838.77s/epoch, Loss=3.22e+4, RMSE=0.9, MAE=0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 5364\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/200 [14:32<48:15:18, 872.96s/epoch, Loss=3.35e+4, RMSE=0.895, MAE=0.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 3076\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/200 [13:32<44:54:54, 812.54s/epoch, Loss=2.79e+4, RMSE=0.909, MAE=0.723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 4214\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/200 [13:42<45:28:48, 822.76s/epoch, Loss=2.96e+4, RMSE=0.908, MAE=0.723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 8079\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/200 [12:48<42:27:55, 768.22s/epoch, Loss=3.18e+4, RMSE=0.898, MAE=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8657465389118378\n",
      "Completed UAutoRec with k=32\n",
      "Running UAutoRec1conf with k=32, use_confounder=True, use_exposure=False\n",
      "random seed run 0: 7473\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:33<00:00,  4.67s/epoch, Loss=1.59e+4, RMSE=0.968, MAE=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 9821\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:46<00:00,  4.73s/epoch, Loss=1.53e+4, RMSE=0.984, MAE=0.788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 9068\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:32<00:00,  4.66s/epoch, Loss=1.55e+4, RMSE=0.988, MAE=0.794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 3880\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:40<00:00,  4.70s/epoch, Loss=1.56e+4, RMSE=0.983, MAE=0.788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 6066\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:40<00:00,  4.70s/epoch, Loss=1.53e+4, RMSE=0.975, MAE=0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8675027349800093\n",
      "Completed UAutoRec1conf with k=32\n",
      "Running UAutoRec1confexp with k=32, use_confounder=True, use_exposure=True\n",
      "random seed run 0: 1400\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:21<00:00,  5.51s/epoch, Loss=1.33e+4, RMSE=1, MAE=0.802]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 3383\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:24<00:00,  5.52s/epoch, Loss=1.38e+4, RMSE=1, MAE=0.8]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 936\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:38<00:00,  5.59s/epoch, Loss=1.33e+4, RMSE=0.999, MAE=0.799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 1815\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:58<00:00,  5.69s/epoch, Loss=1.35e+4, RMSE=1.01, MAE=0.806] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 1373\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n",
      "Train data processed shape: (3706, 6040)\n",
      "Confounder data shape: (3706, 6040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:33<00:00,  5.57s/epoch, Loss=1.35e+4, RMSE=0.985, MAE=0.785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8708582554713791\n",
      "Completed UAutoRec1confexp with k=32\n",
      "Running UAutoRec2conf with k=32, use_confounder=True, use_exposure=False\n",
      "random seed run 0: 1608\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:56<00:00,  4.78s/epoch, Loss=2.73e+4, RMSE=0.908, MAE=0.722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 4720\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:00<00:00,  4.80s/epoch, Loss=2.82e+4, RMSE=0.907, MAE=0.722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 7676\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:05<00:00,  4.83s/epoch, Loss=2.61e+4, RMSE=0.915, MAE=0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 7296\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:03<00:00,  4.82s/epoch, Loss=2.91e+4, RMSE=0.908, MAE=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 4600\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:12<00:00,  4.86s/epoch, Loss=2.58e+4, RMSE=0.921, MAE=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8655477371229608\n",
      "Completed UAutoRec2conf with k=32\n",
      "Running UAutoRec2confexp with k=32, use_confounder=True, use_exposure=True\n",
      "random seed run 0: 5222\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:49<00:00,  5.65s/epoch, Loss=2.97e+4, RMSE=0.904, MAE=0.721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 2760\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:44<00:00,  5.62s/epoch, Loss=2.69e+4, RMSE=0.912, MAE=0.726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 7141\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:48<00:00,  5.64s/epoch, Loss=2.64e+4, RMSE=0.911, MAE=0.726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 4655\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:58<00:00,  5.69s/epoch, Loss=2.73e+4, RMSE=0.899, MAE=0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 6438\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [18:56<00:00,  5.68s/epoch, Loss=2.49e+4, RMSE=0.908, MAE=0.722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8581334188448213\n",
      "Completed UAutoRec2confexp with k=32\n",
      "Running UAutoRec3conf with k=32, use_confounder=True, use_exposure=False\n",
      "random seed run 0: 7411\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:03<00:00,  4.52s/epoch, Loss=3.24e+4, RMSE=0.892, MAE=0.71] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 6311\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [14:48<00:00,  4.44s/epoch, Loss=2.97e+4, RMSE=0.902, MAE=0.717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 2943\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [14:58<00:00,  4.49s/epoch, Loss=3.05e+4, RMSE=0.902, MAE=0.717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 4236\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:01<00:00,  4.51s/epoch, Loss=3.24e+4, RMSE=0.896, MAE=0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 7183\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [14:52<00:00,  4.46s/epoch, Loss=3.14e+4, RMSE=0.896, MAE=0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8658532767679524\n",
      "Completed UAutoRec3conf with k=32\n",
      "Running UAutoRec3confexp with k=32, use_confounder=True, use_exposure=True\n",
      "random seed run 0: 6701\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:08<00:00,  4.84s/epoch, Loss=3.08e+4, RMSE=0.894, MAE=0.71] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 9424\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:15<00:00,  4.88s/epoch, Loss=2.92e+4, RMSE=0.902, MAE=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 1436\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:09<00:00,  4.85s/epoch, Loss=2.63e+4, RMSE=0.912, MAE=0.726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 5484\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:13<00:00,  4.87s/epoch, Loss=2.99e+4, RMSE=0.898, MAE=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 2353\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [16:09<00:00,  4.85s/epoch, Loss=2.98e+4, RMSE=0.902, MAE=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8636009715892026\n",
      "Completed UAutoRec3confexp with k=32\n",
      "Running UAutoRec4conf with k=32, use_confounder=True, use_exposure=False\n",
      "random seed run 0: 2100\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [25:34<00:00,  7.67s/epoch, Loss=2.26e+4, RMSE=0.963, MAE=0.77] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 5683\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [24:47<00:00,  7.44s/epoch, Loss=2.19e+4, RMSE=0.958, MAE=0.762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 6119\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [22:36<00:00,  6.78s/epoch, Loss=2.33e+4, RMSE=0.95, MAE=0.756] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 8920\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [24:24<00:00,  7.32s/epoch, Loss=1.87e+4, RMSE=0.993, MAE=0.795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 8661\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [24:37<00:00,  7.39s/epoch, Loss=1.8e+4, RMSE=0.982, MAE=0.783] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.8984148793935827\n",
      "Completed UAutoRec4conf with k=32\n",
      "Running UAutoRec4confexp with k=32, use_confounder=True, use_exposure=True\n",
      "random seed run 0: 9522\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [35:52<00:00, 10.76s/epoch, Loss=8.91e+3, RMSE=1.05, MAE=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 1: 5563\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [36:21<00:00, 10.91s/epoch, Loss=9.55e+3, RMSE=1.05, MAE=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 2: 345\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [36:22<00:00, 10.91s/epoch, Loss=9.97e+3, RMSE=1.05, MAE=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 3: 7204\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [36:48<00:00, 11.04s/epoch, Loss=9.04e+3, RMSE=1.04, MAE=0.829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed run 4: 1308\n",
      "Train set size: 900191 ratings\n",
      "Test set size: 100022 ratings\n",
      "Load data finished. Number of users: 6040 Number of items: 3706\n",
      "Loaded data: train=(6040, 3706), test=(6040, 3706), user=6040, item=3706\n",
      "UAutoRec with Confounder and Exposure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [36:41<00:00, 11.01s/epoch, Loss=9.16e+3, RMSE=1.04, MAE=0.828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Best RMSE: 0.9890661437257361\n",
      "Completed UAutoRec4confexp with k=32\n"
     ]
    }
   ],
   "source": [
    "def run_all_models(result_path, models, k_values, contype):\n",
    "    for c in contype:\n",
    "        for k in k_values:\n",
    "            for model in models:\n",
    "                use_confounder = 'conf' in model['module_name']\n",
    "                use_exposure = 'exp' in model['module_name']\n",
    "                \n",
    "                print(f\"Running {model['class_name']} with k={k}, use_confounder={use_confounder}, use_exposure={use_exposure}\")\n",
    "                run_model(model['module_name'], model['class_name'], k, c, dat='ml2', use_confounder=use_confounder, use_exposure=use_exposure, test_size=0.1, val_size=0.1, hidden_neuron=500, \n",
    "                        learning_rate=0.001, reg_rate=1, epoch=200, batch_size=512, verbose=True, save_path=result_path, num_runs=5)\n",
    "                \n",
    "                print(f\"Completed {model['class_name']} with k={k}\")\n",
    "\n",
    "result_path = 'C:/Users/Sten Stokroos/Desktop/NEW/zelf/results2'\n",
    "\n",
    "models = [\n",
    "    {'module_name': 'urec_og', 'class_name': 'UAutoRec'},\n",
    "    {'module_name': 'urec_1_conf', 'class_name': 'UAutoRec1conf'},\n",
    "    {'module_name': 'urec_1_confexp', 'class_name': 'UAutoRec1confexp'},\n",
    "    {'module_name': 'urec_2_conf', 'class_name': 'UAutoRec2conf'},\n",
    "    {'module_name': 'urec_2_confexp', 'class_name': 'UAutoRec2confexp'},\n",
    "    {'module_name': 'urec_3_conf', 'class_name': 'UAutoRec3conf'},\n",
    "    {'module_name': 'urec_3_confexp', 'class_name': 'UAutoRec3confexp'},\n",
    "    # {'module_name': 'urec_4_conf', 'class_name': 'UAutoRec4conf'},\n",
    "    # {'module_name': 'urec_4_confexp', 'class_name': 'UAutoRec4confexp'}\n",
    "]\n",
    "\n",
    "k_values = [32]\n",
    "contype = ['hpf']\n",
    "\n",
    "run_all_models(result_path, models, k_values, contype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "import os\n",
    "\n",
    "def compute_statistics(data):\n",
    "    \"\"\"Compute mean, standard deviation, and sample size using .describe() method.\"\"\"\n",
    "    desc = pd.DataFrame(data).describe()\n",
    "    mean = desc.loc['mean'].values\n",
    "    std = desc.loc['std'].values\n",
    "    n = desc.loc['count'].values\n",
    "    return mean, std, n\n",
    "\n",
    "def compute_confidence_intervals(mean, std, n, confidence_level=0.95):\n",
    "    t_value = t.ppf((1 + confidence_level) / 2., n-1)\n",
    "    margin_of_error = t_value * (std / np.sqrt(n))\n",
    "    lower_bound = mean - margin_of_error\n",
    "    upper_bound = mean + margin_of_error\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def load_rmse_values(result_path, models, k_values, contype, epoch, dat):\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        class_name = model['class_name'].lower()\n",
    "        for k in k_values:\n",
    "            rmse_file = os.path.join(result_path, class_name, f'{contype}{epoch}_best_rmse_values_{dat}_k{k}.npy')\n",
    "            if os.path.exists(rmse_file):\n",
    "                rmse_values = np.load(rmse_file)\n",
    "                mean, std, n = compute_statistics(rmse_values)\n",
    "                lower_bound, upper_bound = compute_confidence_intervals(mean, std, n)\n",
    "                results.append({\n",
    "                    'Model': model['class_name'],\n",
    "                    'k': k,\n",
    "                    'Confounder': contype,\n",
    "                    'Mean Best RMSE': mean[0],\n",
    "                    'CI Lower': lower_bound[0],\n",
    "                    'CI Upper': upper_bound[0]\n",
    "                })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df)\n",
    "    return results_df\n",
    "\n",
    "result_path = 'C:/Users/Sten Stokroos/Desktop/NEW/zelf/results2'\n",
    "models = [\n",
    "    {'module_name': 'urec_og', 'class_name': 'UAutoRec'},\n",
    "    {'module_name': 'urec_1_conf', 'class_name': 'UAutoRec1conf'},\n",
    "    {'module_name': 'urec_1_confexp', 'class_name': 'UAutoRec1confexp'},\n",
    "    {'module_name': 'urec_2_conf', 'class_name': 'UAutoRec2conf'},\n",
    "    {'module_name': 'urec_2_confexp', 'class_name': 'UAutoRec2confexp'},\n",
    "    {'module_name': 'urec_3_conf', 'class_name': 'UAutoRec3conf'},\n",
    "    {'module_name': 'urec_3_confexp', 'class_name': 'UAutoRec3confexp'},\n",
    "    # {'module_name': 'urec_4_conf', 'class_name': 'UAutoRec4conf'},\n",
    "    # {'module_name': 'urec_4_confexp', 'class_name': 'UAutoRec4confexp'}\n",
    "]\n",
    "k_values = [32]\n",
    "contype = ['hpf', 'mlp']\n",
    "epoch = 200\n",
    "dat = 'ml2'\n",
    "\n",
    "results_df = load_rmse_values(result_path, models, k_values, contype, epoch, dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model Confounder  Mean Best RMSE  CI Lower  CI Upper\n",
      "0           UAutoRec        hpf        0.937451  0.934960  0.939942\n",
      "1           UAutoRec        mlp        0.937032  0.933485  0.940579\n",
      "2      UAutoRec1conf        hpf        0.935591  0.934503  0.936679\n",
      "3      UAutoRec1conf        mlp        0.936585  0.935669  0.937501\n",
      "4   UAutoRec1confexp        hpf        0.941072  0.940239  0.941905\n",
      "5   UAutoRec1confexp        mlp        0.940575  0.939456  0.941694\n",
      "6      UAutoRec2conf        hpf        0.926922  0.924554  0.929289\n",
      "7      UAutoRec2conf        mlp        0.927007  0.925342  0.928673\n",
      "8   UAutoRec2confexp        hpf        0.921681  0.919984  0.923378\n",
      "9   UAutoRec2confexp        mlp        0.921965  0.920010  0.923921\n",
      "10     UAutoRec3conf        hpf        0.935299  0.932746  0.937853\n",
      "11     UAutoRec3conf        mlp        0.934173  0.931090  0.937256\n",
      "12  UAutoRec3confexp        hpf        0.930171  0.927538  0.932803\n",
      "13  UAutoRec3confexp        mlp        0.931885  0.931326  0.932443\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "import os\n",
    "import re\n",
    "\n",
    "def compute_statistics(data):\n",
    "    \"\"\"Compute mean, standard deviation, and sample size using .describe() method.\"\"\"\n",
    "    desc = pd.DataFrame(data).describe()\n",
    "    mean = desc.loc['mean'].values\n",
    "    std = desc.loc['std'].values\n",
    "    n = desc.loc['count'].values\n",
    "    return mean, std, n\n",
    "\n",
    "def compute_confidence_intervals(mean, std, n, confidence_level=0.95):\n",
    "    t_value = t.ppf((1 + confidence_level) / 2., n-1)\n",
    "    margin_of_error = t_value * (std / np.sqrt(n))\n",
    "    lower_bound = mean - margin_of_error\n",
    "    upper_bound = mean + margin_of_error\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def load_rmse_values(result_path, models, k_values, contype, epoch, dat):\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        class_name = model['class_name'].lower()\n",
    "        for k in k_values:\n",
    "            for c in contype:\n",
    "                best_rmse_values = []\n",
    "                pattern = re.compile(f'{c}{epoch}_run_\\\\d+_test_rmse_{dat}_k{k}.npy')\n",
    "                model_folder = os.path.join(result_path, class_name)\n",
    "                for file in os.listdir(model_folder):\n",
    "                    if pattern.match(file):\n",
    "                        file_path = os.path.join(model_folder, file)\n",
    "                        rmse_values = np.load(file_path)\n",
    "                        best_rmse_values.append(np.min(rmse_values))\n",
    "                \n",
    "                if best_rmse_values:\n",
    "                    mean, std, n = compute_statistics(best_rmse_values)\n",
    "                    lower_bound, upper_bound = compute_confidence_intervals(mean, std, n)\n",
    "                    results.append({\n",
    "                        'Model': model['class_name'],\n",
    "                        'Confounder': c,\n",
    "                        'Mean Best RMSE': mean[0],\n",
    "                        'CI Lower': lower_bound[0],\n",
    "                        'CI Upper': upper_bound[0]\n",
    "                    })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df)\n",
    "    return results_df\n",
    "\n",
    "result_path = 'C:/Users/Sten Stokroos/Desktop/NEW/zelf/results2'\n",
    "models = [\n",
    "    {'module_name': 'urec_og', 'class_name': 'UAutoRec'},\n",
    "    {'module_name': 'urec_1_conf', 'class_name': 'UAutoRec1conf'},\n",
    "    {'module_name': 'urec_1_confexp', 'class_name': 'UAutoRec1confexp'},\n",
    "    {'module_name': 'urec_2_conf', 'class_name': 'UAutoRec2conf'},\n",
    "    {'module_name': 'urec_2_confexp', 'class_name': 'UAutoRec2confexp'},\n",
    "    {'module_name': 'urec_3_conf', 'class_name': 'UAutoRec3conf'},\n",
    "    {'module_name': 'urec_3_confexp', 'class_name': 'UAutoRec3confexp'},\n",
    "    # {'module_name': 'urec_4_conf', 'class_name': 'UAutoRec4conf'},\n",
    "    # {'module_name': 'urec_4_confexp', 'class_name': 'UAutoRec4confexp'}\n",
    "]\n",
    "k_values = [32]\n",
    "contype = ['hpf', 'mlp']\n",
    "epoch = 200\n",
    "dat = 'ml2'\n",
    "\n",
    "results_df = load_rmse_values(result_path, models, k_values, contype, epoch, dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
